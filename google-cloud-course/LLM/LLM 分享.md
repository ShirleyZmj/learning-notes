## 生成式人工智能 （Generative AI ）
### 定义
- 一种人工智能的子集，能够生成文本、图像、音频、合成数据等多种类型的数据。
![[Pasted image 20250404134151.png]]
### 过程
- 通过学习训练数据中的模式和结构，创建具有相似特征的新数据。
![[Pasted image 20250404134419.png]]

### 应用
- 生成式 AI 在各个行业中都有应用，包括软件开发、医疗保健、金融、娱乐、客户服务和销售。
![[Pasted image 20250404135103.png]]
 
## 大型语言模型 (Large Language Models, LLMs)
![[Pasted image 20250404135507.png]]
### 定义
- 大型语言模型指的是可以预先训练并针对特定目的进行微调的大型通用语言模型。

#### Large - 大:
- 训练数据集的大小，有时可以达到 PB 级别。（1 PB = 1,024 TB = 1,048,576 GB）
- 参数数量，
	- 参数：是机器在模型训练期间学到的记忆和知识，它们决定了模型解决诸如预测文本等问题的能力，其规模可以达到数十亿甚至数万亿
#### General-purpose - 通用的
- 模型可以充分地解决常见问题
#### pre-trained - 预训练
- 大语言模型首先会在**海量的通用文本数据**（比如书籍、网页、对话等）上进行训练，这个过程叫做**预训练**。  
- 这个阶段的目标是让模型学会语言的结构、语法、上下文理解能力、世界知识等。它就像是“打基础”——让模型具备广泛的语言理解和生成能力，能够模拟人类语言的理解和生成。
	- 猜下一个单词是什么（语言建模）
	- 不同语境下同一个词的含义
	- 不同任务（问答、摘要、翻译）的语言模式
- 类比：上大学打通识教育基础
#### fine-tuned - 微调
- 用更小的数据集对特定目标进行微调
- 预训练之后，模型可能还需要被**微调**，也就是在**更小、但更有针对性的训练集**上再次训练。这个阶段是为了让模型在某个特定任务或领域（比如法律、医疗、编程）表现更好。
- 微调就像是“专业训练”——
	- 比如把一个通用模型微调成能写代码的模型
	- 或者让它适应某个公司内部的对话风格或特定的业务需求
- 类比：毕业后进入特定行业培训，成为专业人士
#### pre-trained and fine-tuned
- 模型先用大规模通用数据打基础（预训练），再用小规模的专业数据做强化训练（微调），以达到更具体的目标。


## 如何训练语言模型

 - 大语言模型通过“预训练”学习语言的结构和知识，本质上是在学习“如何合理地补全一段话”，因此它就像一个聪明的自动补全工具，能根据你输入的提示预测出最合适的回应。
1.  当你输入一个提示（prompt）给 LLM 时，它会从预训练好的模型中计算出一个“最可能正确的回答”。
	- 也就是说，模型不会“理解”你的问题像人类那样去思考，而是会根据以前训练学到的模式，**计算出最可能出现的词或句子**作为回应。
2. 这个“可能性”的判断力是通过“预训练”学来的。
	- 所谓“预训练”就是模型在大量数据上学习各种语言模式的过程。它通过反复试图“预测下一个词”来学语言的结构、常识、表达方式等。
3. 模型的预训练过程会喂给它巨量的数据，比如文本、图片和代码，让它学会语言的底层结构和规律。
	- 太阳在___上，需要让它联想到 天空
	- 重复成千上万次，它就会发现“太阳”“在”“天空”经常一起出现
	- 还会学到英文/中文的语法、句式、逻辑结构
	- 如果训练数据里有图像和代码，它也能学到视觉或编程语言的模式
4. 所以从本质上说，LLM 就像一个“超级高级的自动补全工具”——它只是不断地预测“接下来最有可能是什么”。
	- 比如你打字时，手机会建议你下一个词。LLM 也是一样的机制，只不过更强大，可以生成整段逻辑通顺、有信息量的内容。

![[Pasted image 20250404150243.png]]
![[Pasted image 20250404150330.png]]
### 模型是如何处理这个句子的 The sun is in the
1. 模型会预测下一个词出现的概率
2. 错误原因分析
	- 为什么会匹配bed呢
		- 可能模型里有很多 The son is in the bed. The cat is in the bed.
		-  把它当作“son”的拼写错误或乱码；
		- 直接忽略它的意义，只看句子结构；
		- 回归到自己熟悉的语言模式去预测。
	- 这在它的经验里（训练语料中）是最“合理”或“常见”的语言结构。
	- 那 sky 为什么概率很低？
		- 训练数据里出现这样的匹配不多 
3. 类比：就像你看泰文/韩语书写，你一个字都看不懂，你就只能按照之前见过的例子去猜测。

### 大语言模型（LLM）是怎么确认某个词的概率的？
 - 解释： **模型通过“训练学到的参数”和“当前上下文”来计算每一个词的概率。**
 - [[大语言模型（LLM）是怎么确认某个词的概率的]]
 
---
## 幻觉 Hallucination

- 解释： LLM生成不准确或无意义的内容。
	- AI 会“胡说八道”，有时候你问 AI（比如 ChatGPT）一个问题，它的回答听起来很像是对的，但其实完全错了
	-  **AI 胡乱编造了一些听起来像真的，但实际上是错误或毫无意义的内容。**

### 🧠 为什么 AI 会产生幻觉？

大语言模型（LLM）像是一个超级强大的“猜词游戏选手”。它不是在“思考”，它只是根据过去见过的海量数据来“猜测”最可能的答案。但它有几个局限：

1. **只能理解它看过的资料**  
   它不知道你公司内部的信息，也不了解专业领域的秘密。

2. **没有实时连接互联网**  
   它不清楚世界上刚发生的事情（比如最新的新闻、股市变化）。

3. **无法确认问题是否正确**  
   如果你问了一个“看起来合理但其实错误”的问题，它会直接回答，而不会质疑或反问。

4. **无法询问更多上下文信息**  
   它不会像人一样说：“你具体是指哪个方面呢？”

---

### 🚨 幻觉的常见原因

造成 AI 幻觉的常见原因包括：

- 🧾 **训练数据不够多或不够好**：它可能没看过相关内容，或者看到的内容本身就有误。
- 🧹 **数据太杂乱**：有些数据是错误的，模型也学进去了。
- 📏 **上下文不完整**：你提供的信息太少，它只能靠“猜”。
- 🚧 **没有限制输出范围**：它不知道哪些话不能乱说。

---

### 😕 为什么幻觉是个问题？

- 🔄 **可能误导人**：让你以为它说的是对的，其实是错的。
- 🧩 **让人更难理解**：输出的内容有时逻辑混乱、文法错误，看了让人困惑。

---

#### ✅ 最重要的一句话：

> AI（大语言模型）并不真的“懂”你问的问题，它只是“根据模式来猜”你想要的答案。

所以我们在使用 AI 时，也需要保持一定的判断力。如果你觉得某个回答听起来不对，那可能就是不对！

--- 
### 🧰 如何减少幻觉？这就要用到提示工程（Prompt Engineering）

AI 有时会胡说八道，但我们可以通过一种技巧让它“说得更靠谱”——这就是 **提示工程（Prompt Engineering）**。

#### ❓ 什么是提示工程？ ---- 怎么问比问什么更重要

简单说，就是：

> **我们如何问问题，会影响 AI 的回答质量。** 
> **我们要学会用更清晰、结构更好的方式问问题，让 AI 给出更准确、更靠谱的回答。**

就像跟人沟通时，如果你问题问得模糊，别人也可能答非所问；但如果你说得清楚具体，别人往往就能给你满意的答复。

---
#### ❓ 什么是提示
- 是给计算机的特定指令、问题或线索
	- “提示”就是你给 AI 发的那句话，比如：
```text
请告诉我法国的首都。
```
- 提示给得越好，得到的回答越符合期待


#### 提示的类型
![[Pasted image 20250404164429.png]]

| 类型                       | 举例                       | 特点               |
| ------------------------ | ------------------------ | ---------------- |
| **Zero-shot（零样本）**       | “法国的首都是哪里？”              | 没有提供任何例子或背景      |
| **One-shot（单样本）**        | “意大利的首都是罗马，那么法国的首都是？”    | 提供一个例子帮助理解       |
| **Few-shot（少样本）**        | “意大利-罗马，日本-东京。法国的首都是？”   | 提供多个例子，帮助模型掌握规律  |
| **Role prompting（设定角色）** | “你现在是一位经济学教授，请解释什么是ROI。” | 给模型设定身份 + 明确任务场景 |

![[Pasted image 20250404164528.png]]

#### 🧩 提示的两个关键部分

![[Pasted image 20250404164733.png]]

为了让提示更有效，一般分为两个部分：
### 1. Preamble（前言/铺垫）

前言是给 AI 的“背景介绍”。你可以告诉它：

- 你要它扮演什么角色（老师、医生、编辑等）
    
- 你希望它怎么回答（专业、简洁、详细…）
    
- 是否提供例子帮助它理解
    

比如：

```text
你是美食评论家，请根据我提供的评论判断它是正面、负面还是中性。
```

---

### 2. Input（输入）

这是你真正想让 AI 处理的内容，比如：

```text
评论内容：“这个视频我看不懂，说不出好坏。”
```

---

AI 就会根据前言 + 输入来判断：这是“中性评论”。

---


### 🛠 提示工程的几个小技巧（举例说明）

| 方式     | 例子                                | 效果          |
| ------ | --------------------------------- | ----------- |
| ✅ 问得具体 | ❌ “介绍一下长城”<br>✅ “用100字介绍长城的历史和意义” | 更聚焦、避免跑题    |
| ✅ 设定角色 | “假设你是一位历史老师，解释一下这个事件。”            | 回答更专业、更贴合语境 |
| ✅ 要求格式 | “请用表格列出优缺点”                       | 输出更清晰、可读性高  |
| ✅ 限制范围 | “只说2023年以后的数据”                    | 避免使用过时信息    |
|        |                                   |             |

---


## ✍️ 提示工程的最佳实践（Best Practices）

我们已经了解了什么是提示（Prompt），以及提示工程的几种方式。  
那接下来，就是掌握一些“小窍门”，让 AI 回答得更靠谱、更聪明！

---

### ✅ 1. 写得越清楚越好！

**模糊的问题 = 模糊的答案。**

例如：

```text
不好的提示：写一个总结。
好的提示：请用100字以内，总结这篇文章的主要观点，并用通俗语言表达。
````

---

### ✅ 2. 告诉它你想要什么，而不是“不想要什么”

比如：

```text
❌ 不太好：请不要写得太长。
✅ 更好：请将回答限制在三句话以内。
```

AI 对“不要做什么”理解得不好，它更擅长“照着做什么”。

---

### ✅ 3. 设定“兜底答案”

如果问题超出它知识范围，它可能乱猜。  
可以给它准备一个“兜底回答”来避免误导。

例如：

```text
如果你不知道答案，请回答：“我还在学习这个问题。”
```

---

### ✅ 4. 给 AI 设定角色（Persona）

角色能让 AI 更聚焦、少跑题。

比如：

```text
你是一位有20年经验的医生，现在请解释‘高血压’的原因，要求用简单语言说清楚。
```

你设定好身份，它就“入戏”了。

---

### ✅ 5. 保持句子简短、任务清晰

AI 有时对**长句或复合任务**理解得不够好。  
建议把问题分成**几句简单的小句子**。

比如：

```text
❌ 不太好：我想让你帮我设计网络架构，要支持多区域连接，还要能集中管理防火墙策略，而且要简单维护。
✅ 更好：你是一位云架构师。你想设计一个 Google Cloud 的 VPC 网络。它需要支持跨区域连接。你希望能集中管理防火墙策略，减少维护工作。请推荐一个网络架构方案。
```

结构清晰，AI 更容易理解，也更容易给出符合预期的答案。

---

## 🧑‍💻 真实示例：Sasha 的提问改进

Sasha 是一位云架构师。她最初的问题比较模糊，但后来她这样改写了提示：

```text
你是一位云架构师。你希望构建一个可以集中管理的 Google Cloud VPC 网络。  
你还要连接公司其他区域的 VPC 网络，不想维护太多不同的防火墙策略。  
你会推荐什么样的网络架构？
```

💡 AI 给出了“星型（hub-and-spoke）网络架构”作为建议，正好满足她的需求！

---

## 总结一句话：

就像你和别人聊天，说得越清楚、越有礼貌，别人越容易帮到你。  
跟 AI 沟通也是同样的道理。我们要学会“怎么好好说话”，它才听得懂、答得好。

---

## 🧾 Prompt 小抄模板合集（给不会写提示的人）

以下是一些常用场景的 Prompt 模板，你只需要把自己的内容填进去即可使用：

---

### 📚 1. 帮我总结文章 / 视频 / 内容

```text
请帮我总结下面这段内容，用100字以内、简单易懂的话来说清楚重点：
[贴上内容]
````

---

### 👩‍🏫 2. 解释一个专业名词（用给小白听得懂的方式）

```text
你是一位有耐心的老师，请用简单语言告诉我：“[术语名]”是什么意思，就像给家人解释一样。
```

---

### 📖 3. 翻译成“通俗说法”

```text
请把下面这段内容翻译成普通人能听懂的话，不用太多专业术语：
[贴上原文]
```

---

### 💡 4. 帮我想创意 / 点子 / 名字

```text
我需要一些创意，请给我10个点子：[你的需求，比如 店名、公众号名、活动主题 等]
```

---

### 🎨 5. 写个温柔一点、好听一点的版本

```text
请把下面这段话改写得更温柔、适合发朋友圈或者发给朋友：
[贴上原文]
```

---

### 🧠 6. 帮我做个决定（分析优缺点）

```text
我在考虑这两个选择：[选择A] 和 [选择B]。请帮我分析一下它们的优点和缺点，建议我怎么选。
```

---

### 📅 7. 帮我列个计划 / 时间表

```text
我想在 [时间范围，比如1个月] 内完成 [目标，比如学会Python入门]，请帮我制定一个简单可执行的计划。
```

---

### 🛠 8. 假设你是个专家，给我专业建议

```text
你是一位有10年经验的 [职业，例如 营养师 / 健身教练 / 老师 / 理财顾问]，请就这个问题给我专业建议：
[你的问题]
```

---


# 提示网站
- [deepseek官方提示语库](https://api-docs.deepseek.com/zh-cn/prompt-library/)
- [1Prompt](https://1prompt.top/)

- [Google Al Studio](https://aistudio.google.com/app/prompts)
- [Hero Prompt Library](https://hero.page/discover)
- [Snack Prompt](https://snackprompt.com/prompts)
- [OpenAl Prompt Library](https://platform.openai.com/docs/examples)
- [Anthropic Prompt Library](https://docs.anthropic.com/en/docs/prompt-engineering/prompt-library)
- [PromptHero](https://www.prompthero.com/)
- [Github ChatGPT Prompts](https://github.com/pacholoamit/chatgpt-prompts)
